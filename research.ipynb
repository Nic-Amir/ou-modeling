{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt, exp, log  # exp(n) == e^n, log(n) == ln(n)\n",
    "import scipy.optimize as so\n",
    "import numpy as np\n",
    "\n",
    "def compute_log_likelihood(params, *args):\n",
    "    '''\n",
    "    Compute the average Log Likelihood, this function will by minimized by scipy.\n",
    "    Find in (2.2) in linked paper\n",
    "\n",
    "    returns: the average log likelihood from given parameters\n",
    "    '''\n",
    "    # functions passed into scipy's minimize() needs accept one parameter, a tuple of\n",
    "    #   of values that we adjust to minimize the value we return.\n",
    "    #   optionally, *args can be passed, which are values we don't change, but still want\n",
    "    #   to use in our function (e.g. the measured heights in our sample or the value Pi)\n",
    "\n",
    "    theta, mu, sigma = params\n",
    "    X, dt = args\n",
    "    n = len(X)\n",
    "\n",
    "    sigma_tilde_squared = sigma ** 2 * (1 - exp(-2 * mu * dt)) / (2 * mu)\n",
    "    summation_term = 0\n",
    "\n",
    "    for i in range(1, len(X)):\n",
    "        summation_term += (X[i] - X[i - 1] * exp(-mu * dt) - theta * (1 - exp(-mu * dt))) ** 2\n",
    "\n",
    "    summation_term = -summation_term / (2 * n * sigma_tilde_squared)\n",
    "\n",
    "    log_likelihood = (-log(2 * math.pi) / 2) + (-log(sqrt(sigma_tilde_squared))) + summation_term\n",
    "\n",
    "    return -log_likelihood\n",
    "    # since we want to maximize this total log likelihood, we need to minimize the\n",
    "    #   negation of the this value (scipy doesn't support maximize)\n",
    "\n",
    "\n",
    "def estimate_coefficients_MLE(X, dt, tol=1e-10):\n",
    "    '''\n",
    "    Estimates Ornstein-Uhlenbeck coefficients (θ, µ, σ) of the given array\n",
    "    using the Maximum Likelihood Estimation method\n",
    "\n",
    "    input: X - array-like time series data to be fit as an OU process\n",
    "           dt - time increment (1 / days(start date - end date))\n",
    "           tol - tolerance for determination (smaller tolerance means higher precision)\n",
    "    returns: θ, µ, σ, Average Log Likelihood\n",
    "    '''\n",
    "\n",
    "    bounds = ((None, None), (1e-5, None), (1e-5, None))  # theta ∈ ℝ, mu > 0, sigma > 0\n",
    "                                                           # we need 1e-10 b/c scipy bounds are inclusive of 0, \n",
    "                                                           # and sigma = 0 causes division by 0 error\n",
    "    theta_init = np.mean(X)\n",
    "    initial_guess = (theta_init, 100, 100)  # initial guesses for theta, mu, sigma\n",
    "    result = so.minimize(compute_log_likelihood, initial_guess, args=(X, dt), bounds=bounds, tol=tol)\n",
    "    theta, mu, sigma = result.x \n",
    "    max_log_likelihood = -result.fun  # undo negation from __compute_log_likelihood\n",
    "    # .x gets the optimized parameters, .fun gets the optimized value\n",
    "    return theta, mu, sigma, max_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_portfolio_values(ts_A, ts_B, alloc_B):\n",
    "    '''\n",
    "    Compute the portfolio values over time when holding $1 of stock A \n",
    "    and -$alloc_B of stock B\n",
    "    \n",
    "    input: ts_A - time-series of price data of stock A,\n",
    "           ts_B - time-series of price data of stock B\n",
    "    outputs: Portfolio values of holding $1 of stock A and -$alloc_B of stock B\n",
    "    '''\n",
    "    \n",
    "    ts_A = ts_A.copy()  # defensive programming\n",
    "    ts_B = ts_B.copy()\n",
    "    \n",
    "    ts_A = ts_A / ts_A[0]\n",
    "    ts_B = ts_B / ts_B[0]\n",
    "    return ts_A - alloc_B * ts_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_max_B_alloc(ts_A, ts_B, dt):\n",
    "    '''\n",
    "    Finds the $ allocation ratio to stock B to maximize the log likelihood\n",
    "    from the fit of portfolio values to an OU process\n",
    "\n",
    "    input: ts_A - time-series of price data of stock A,\n",
    "           ts_B - time-series of price data of stock B\n",
    "           dt - time increment (1 / days(start date - end date))\n",
    "    returns: θ*, µ*, σ*, B*\n",
    "    '''\n",
    "    \n",
    "    theta = mu = sigma = alloc_B = 0\n",
    "    max_log_likelihood = 0\n",
    "\n",
    "    def compute_coefficients(x):\n",
    "        portfolio_values = compute_portfolio_values(ts_A, ts_B, x)\n",
    "        return estimate_coefficients_MLE(portfolio_values, dt)\n",
    "    \n",
    "    vectorized = np.vectorize(compute_coefficients)\n",
    "    linspace = np.linspace(.01, 1, 100)\n",
    "    res = vectorized(linspace)\n",
    "    index = res[3].argmax()\n",
    "    \n",
    "    return res[0][index], res[1][index], res[2][index], linspace[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, exp\n",
    "import scipy.integrate as si\n",
    "import scipy.optimize as so\n",
    "import numpy as np\n",
    "\n",
    "def Prime(f, x, theta, mu, sigma, r, h=1e-5):\n",
    "    # given f, estimates f'(x) using the difference quotient formula \n",
    "    # WARNING: LOWER h VALUES CAN LEAD TO WEIRD RESULTS\n",
    "    return (f(x+h, theta, mu, sigma, r) - f(x, theta, mu, sigma, r)) / h \n",
    "\n",
    "def Prime2(f, x, theta, mu, sigma, r, c, h=1e-5):\n",
    "    # given f, estimates f'(x) using the difference quotient formula \n",
    "    # WARNING: LOWER h VALUES CAN LEAD TO WEIRD RESULTS\n",
    "    return (f(x+h, theta, mu, sigma, r, c) - f(x, theta, mu, sigma, r, c)) / h \n",
    "\n",
    "def F(x, theta, mu, sigma, r):\n",
    "    # equation 3.3\n",
    "    def integrand(u):\n",
    "        return u**(r/mu - 1) * exp(sqrt(2*mu / sigma**2) * (x-theta)*u - u**2/2)\n",
    "    return si.quad(integrand, 0, np.inf)[0]\n",
    "\n",
    "def G(x, theta, mu, sigma, r):\n",
    "    # equation 3.4\n",
    "    def integrand(u):\n",
    "        return u**(r/mu - 1) * exp(sqrt(2*mu / sigma**2) * (theta-x)*u - u**2/2)\n",
    "    return si.quad(integrand, 0, np.inf)[0]\n",
    "\n",
    "def b_star(theta, mu, sigma, r, c):\n",
    "    # estimates b* using equation 4.3\n",
    "    # def opt_func(b):\n",
    "    #     # equation 4.3 in the paper with terms moved to one side\n",
    "    #     return abs(F(b, theta, mu, sigma, r) - (b-c)*Prime(F, b, theta, mu, sigma, r))\n",
    "    # bounds = ((.01, .99),)\n",
    "    # result = so.minimize(opt_func, .5, bounds=bounds)\n",
    "\n",
    "    b_space = np.linspace(0.1,0.9, 801)\n",
    "    def func(b):\n",
    "        return F(b, theta, mu, sigma, r) - (b-c)*Prime(F, b, theta, mu, sigma, r)\n",
    "    \n",
    "    return so.brentq(func, 0, 1)\n",
    "\n",
    "def V(x, theta, mu, sigma, r, c):\n",
    "    # OUR SELL SIGNAL\n",
    "    # equation 4.2, solution of equation posed by 2.3\n",
    "    \n",
    "    b_star_val = b_star(theta, mu, sigma, r, c)\n",
    "    \n",
    "    if x < b_star_val:\n",
    "        return (b_star_val - c) * F(x, theta, mu, sigma, r) / F(b_star_val, theta, mu, sigma, r)\n",
    "    else:\n",
    "        return x - c\n",
    "\n",
    "def d_star(theta, mu, sigma, r, c):\n",
    "    # estimates d* using equation 4.11\n",
    "  \n",
    "    def func(d):\n",
    "        return (G(d, theta, mu, sigma, r) * (Prime2(V, d, theta, mu, sigma, r, c) - 1)) - (Prime(G, d, theta, mu, sigma, r) * (V(d, theta, mu, sigma, r, c) - d - c))\n",
    "\n",
    "    # finds the root between the interval [0, 1]\n",
    "    return so.brentq(func, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"USDCHF-sigma1.0-5-10-10-10-4.csv\")\n",
    "df[\"ts\"] = pd.to_datetime(df[\"Unnamed: 0\"])\n",
    "df = df.set_index(\"ts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts\n",
       "2022-10-25 23:55:00    112296.367826\n",
       "2022-10-25 23:56:00    112379.196436\n",
       "2022-10-25 23:57:00    112391.671297\n",
       "2022-10-25 23:58:00    112366.810686\n",
       "2022-10-25 23:59:00    112546.243644\n",
       "Name: Index, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.resample(\"1min\").mean()\n",
    "\n",
    "ts_A1 = df[df[\"Index\"].notna()]\n",
    "ts_A2 = ts_A1['Index']\n",
    "\n",
    "ts_B1 = df[df[\"FX\"].notna()]\n",
    "ts_B2 = ts_A1['FX']\n",
    "\n",
    "\n",
    "mins = (df.index[-1] - df.index[0]).seconds / (60)\n",
    "dt1 = 1 / mins\n",
    "\n",
    "ts_A2.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, mu, sigma, alloc_B = arg_max_B_alloc(ts_A2,ts_B2,dt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20419935234044176, 0.030492090124698303, 0.03975767810771347, 1.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta, mu, sigma, alloc_B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
